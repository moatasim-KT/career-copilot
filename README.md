# ğŸš€ Career Copilot# ğŸš€ Career Copilot# ğŸš€ Career Copilot# Career Copilot ğŸš€



[![Python Version](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/downloads/)

[![FastAPI](https://img.shields.io/badge/FastAPI-0.109%2B-009688.svg)](https://fastapi.tiangolo.com/)

[![Next.js](https://img.shields.io/badge/Next.js-14.0-black.svg)](https://nextjs.org/)[![Python Version](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/downloads/)

[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

[![FastAPI](https://img.shields.io/badge/FastAPI-0.109%2B-009688.svg)](https://fastapi.tiangolo.com/)

> **AI-Powered Job Application Tracking and Career Management System**

[![Next.js](https://img.shields.io/badge/Next.js-14.0-black.svg)](https://nextjs.org/)[![Python Version](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/downloads/)[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Career Copilot is an intelligent career management platform that helps job seekers streamline their job search, track applications, prepare for interviews, and receive personalized career guidance through AI-powered insights.

[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

[![FastAPI](https://img.shields.io/badge/FastAPI-0.109%2B-009688.svg)](https://fastapi.tiangolo.com/)[![Python Version](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/downloads/)

## ğŸ¯ Project Overview

> **AI-Powered Job Application Tracking and Career Management System**

### What is Career Copilot?

[![Next.js](https://img.shields.io/badge/Next.js-14.0-black.svg)](https://nextjs.org/)[![Node Version](https://img.shields.io/badge/node-18.x%2B-green.svg)](https://nodejs.org/)

Career Copilot is a comprehensive career management platform designed to transform the job search experience. It combines modern web technologies with artificial intelligence to provide intelligent job discovery, application tracking, and career development tools.

Career Copilot is an intelligent career management platform that helps job seekers streamline their job search, track applications, prepare for interviews, and receive personalized career guidance through AI-powered insights.

### Key Features

[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)[![FastAPI](https://img.shields.io/badge/FastAPI-0.109%2B-009688.svg)](https://fastapi.tiangolo.com/)

#### ğŸ” **Job Discovery & Aggregation**

- Multi-source job scraping (Adzuna, The Muse, RapidAPI JSEarch)---

- Automated daily job ingestion at 4:00 AM

- Smart deduplication across sources[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)]()[![Next.js](https://img.shields.io/badge/Next.js-14.0-black.svg)](https://nextjs.org/)

- Location-based filtering (European countries supported)

- Role-specific searches (Data Science, ML Engineer, AI Engineer, Data Analyst)## ğŸ“‹ Table of Contents



#### ğŸ“Š **Application Tracking**

- Kanban-style application board

- Custom application stages and workflows- [Project Overview](#project-overview)

- Deadline tracking and automated reminders

- Notes and document attachments per application- [Architecture & Design](#architecture--design)> **AI-Powered Job Application Tracking and Career Management System**> AI-Powered Job Application Tracking and Career Management System

- Timeline view of application history

- [Components & Modules](#components--modules)

#### ğŸ¤– **AI-Powered Features**

- Resume analysis and optimization suggestions- [Prerequisites](#prerequisites)

- Custom cover letter generation for each job

- Interview question generation based on job descriptions- [Installation & Setup](#installation--setup)

- Mock interview practice with AI feedback

- Employment contract analysis and insights- [External APIs & Services](#external-apis--services)Career Copilot is an intelligent career management platform that helps job seekers streamline their job search, track applications, prepare for interviews, and receive personalized career guidance through AI-powered insights.Career Copilot is a comprehensive, enterprise-grade platform that helps job seekers manage their career journey with the power of AI. Track applications, get personalized job recommendations, generate tailored resumes and cover letters, practice interviews, and gain insights into your job search progressâ€”all in one place.

- Skill gap identification and learning recommendations

- [Configuration](#configuration)

#### ğŸ“ˆ **Analytics & Insights**

- Application success rate metrics- [Usage & Functionality](#usage--functionality)

- Response time analytics across companies

- Skills gap analysis with market trends- [API Documentation](#api-documentation)

- Industry-specific insights and recommendations

- Interactive performance dashboards- [Development Guidelines](#development-guidelines)------



#### ğŸ”” **Notifications & Automation**- [Troubleshooting](#troubleshooting)

- Morning briefings (8:00 AM) with job matches

- Evening summaries (8:00 PM) with daily progress- [Production Deployment](#production-deployment)

- Email notifications for application updates

- Automated job matching based on user preferences- [Additional Resources](#additional-resources)

- Smart follow-up reminders

## ğŸ“‹ Table of Contents## ğŸ“‹ Table of Contents

### Target Audience

---

- **Job Seekers**: Professionals actively searching for new opportunities

- **Career Changers**: Individuals transitioning to data science, ML, or AI roles

- **Recent Graduates**: Entry to mid-level candidates entering the tech job market

- **European Job Market**: Optimized for positions in Germany, Netherlands, France, UK, and other EU countries## ğŸ¯ Project Overview



### Technology Highlights- [Project Overview](#-project-overview)- [Features](#-features)



- **Modern Stack**: FastAPI + Next.js + PostgreSQL### What is Career Copilot?

- **AI Integration**: OpenAI GPT-4, Groq (Llama 3), Google Gemini

- **Real-time Updates**: WebSocket support for live notifications- [Architecture & Design](#-architecture--design)- [Architecture](#-architecture--design)

- **Scalable Architecture**: Async operations, background tasks with Celery

- **Secure**: OAuth 2.0, JWT authentication, encrypted API keysCareer Copilot is a comprehensive career management platform designed to transform the job search experience. It combines modern web technologies with artificial intelligence to provide intelligent job discovery, application tracking, and career development tools.

- **Production-Ready**: Docker support, monitoring with Prometheus/Grafana

- [Components & Modules](#-components--modules)- [Technology Stack](#-technology-stack)

---

### Key Features

- [Prerequisites](#-prerequisites)- [Prerequisites](#-prerequisites)

#### ğŸ” **Job Discovery & Aggregation**

- Multi-source job scraping (Adzuna, The Muse, RapidAPI JSEarch)- [Installation & Setup](#-installation--setup)- [Quick Start](#-quick-start)

- Automated daily job ingestion at 4:00 AM

- Smart deduplication across sources- [External APIs & Services](#-external-apis--services)- [Installation & Setup](#-installation--setup)

- Location-based filtering (European countries supported)

- Role-specific searches (Data Science, ML Engineer, AI Engineer, Data Analyst)- [Configuration](#-configuration)- [External APIs & Services](#-external-apis--services)



#### ğŸ“Š **Application Tracking**- [Usage & Functionality](#-usage--functionality)- [Configuration](#-configuration)

- Kanban-style application board

- Custom application stages and workflows- [API Documentation](#-api-documentation)- [Usage](#-usage--functionality)

- Deadline tracking and automated reminders

- Notes and document attachments per application- [Development Guidelines](#-development-guidelines)- [API Documentation](#-api-documentation)

- Timeline view of application history

- [Troubleshooting](#-troubleshooting)- [Development Guidelines](#-development-guidelines)

#### ğŸ¤– **AI-Powered Features**

- Resume analysis and optimization suggestions- [Production Deployment](#-production-deployment)- [Testing](#-testing)

- Custom cover letter generation for each job

- Interview question generation based on job descriptions- [Additional Resources](#-additional-resources)- [Production Deployment](#-production-deployment)

- Mock interview practice with AI feedback

- Employment contract analysis and insights- [Troubleshooting](#-troubleshooting)

- Skill gap identification and learning recommendations

---- [Contributing](#-contributing)

#### ğŸ“ˆ **Analytics & Insights**

- Application success rate metrics- [License](#-license)

- Response time analytics across companies

- Skills gap analysis with market trends## ğŸ¯ Project Overview

- Industry-specific insights and recommendations

- Interactive performance dashboards---



#### ğŸ”” **Notifications & Automation**### What is Career Copilot?

- Morning briefings (8:00 AM) with job matches

- Evening summaries (8:00 PM) with daily progress## âœ¨ Features

- Email notifications for application updates

- Automated job matching based on user preferencesCareer Copilot is a comprehensive career management platform designed to transform the job search experience. It combines modern web technologies with artificial intelligence to provide:

- Smart follow-up reminders

### Core Functionality

### Target Audience

- **Smart Job Tracking**: Automated job discovery from multiple sources (Adzuna, The Muse, RapidAPI JSEarch)- **ğŸ“Š Application Tracking**: Comprehensive job application lifecycle management with status tracking (interested, applied, interview, offer, rejected, accepted, declined)

- **Job Seekers**: Professionals actively searching for new opportunities

- **Career Changers**: Individuals transitioning to data science, ML, or AI roles- **AI-Powered Insights**: Resume analysis, cover letter generation, and interview preparation using OpenAI/Groq- **ğŸ¯ Smart Job Recommendations**: AI-powered job matching based on skills, experience, and preferences

- **Recent Graduates**: Entry to mid-level candidates entering the tech job market

- **European Job Market**: Optimized for positions in Germany, Netherlands, France, UK, and other EU countries- **Application Management**: Track applications across different stages with kanban-style boards- **ğŸ“ AI Content Generation**: Automated resume and cover letter generation tailored to each job posting



### Technology Highlights- **Interview Practice**: AI-driven mock interviews with real-time feedback- **ğŸ¤ Interview Practice**: Interactive AI-powered interview preparation with feedback



- **Modern Stack**: FastAPI + Next.js + PostgreSQL- **Career Analytics**: Performance metrics, application success rates, and personalized recommendations- **ğŸ“ˆ Analytics Dashboard**: Visual insights into application progress, success rates, and trends

- **AI Integration**: OpenAI GPT-4, Groq (Llama 3), Google Gemini

- **Real-time Updates**: WebSocket support for live notifications- **Document Generation**: Auto-generate tailored resumes and cover letters for specific job postings- **ğŸ” Job Search & Scraping**: Automated job discovery from multiple sources (LinkedIn, Indeed, Adzuna, etc.)

- **Scalable Architecture**: Async operations, background tasks with Celery

- **Secure**: OAuth 2.0, JWT authentication, encrypted API keys- **Contract Analysis**: Parse and analyze employment contracts for key terms and red flags- **ğŸ”” Smart Notifications**: Customizable email alerts for deadlines, follow-ups, and job matches

- **Production-Ready**: Docker support, monitoring with Prometheus/Grafana



---

### Key Features### Advanced Features


- **ğŸ¤– Multi-LLM Support**: Integration with OpenAI GPT-4, Groq (Llama), Anthropic Claude, and Google Gemini

#### ğŸ” **Job Discovery & Aggregation**- **ğŸ¯ Intelligent Routing**: Adaptive model selection based on task complexity and performance

- Multi-source job scraping (Adzuna, The Muse, RapidAPI JSEarch)- **ğŸ’¾ Vector Storage**: Semantic search capabilities using ChromaDB for job matching

- Automated daily job ingestion- **ğŸ“Š Real-time Analytics**: Advanced user behavior tracking and predictive insights

- Smart deduplication across sources- **ğŸ” Enterprise Security**: OAuth2, JWT authentication, RBAC, and comprehensive audit trails

- Location-based filtering (supports European countries)- **ğŸ“¤ Export & Backup**: Automated backups and data export in multiple formats

- Role-specific searches (Data Science, ML Engineer, AI Engineer, Data Analyst)- **ğŸŒ Multi-provider OAuth**: Support for Google, GitHub, and LinkedIn authentication

- **âš¡ Background Task Processing**: Celery-based async job queue for heavy operations

#### ğŸ“Š **Application Tracking**- **ğŸ“§ Email Automation**: Scheduled digests, alerts, and personalized notifications

- Kanban-style application board- **ğŸ¨ Customizable Dashboards**: User-configurable layouts and widgets

- Custom application stages and workflows

- Deadline tracking and reminders---

- Notes and document attachments

- Timeline view of application history## ğŸ—ï¸ Architecture & Design



#### ğŸ¤– **AI-Powered Features**### High-Level Architecture

- Resume analysis and optimization

- Custom cover letter generationCareer Copilot follows a modern **microservices-inspired monolithic architecture** with clear separation of concerns:

- Interview question generation based on job descriptions

- Mock interview practice with AI feedback```

- Contract analysis and insightsâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚                     Frontend (Next.js)                      â”‚

#### ğŸ“ˆ **Analytics & Insights**â”‚  - React Components - TypeScript - TailwindCSS - Recharts  â”‚

- Application success rate metricsâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- Response time analytics                     â”‚ REST API / WebSocket

- Skills gap analysisâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

- Industry trends and recommendationsâ”‚                  API Layer (FastAPI)                        â”‚

- Performance dashboardsâ”‚  - Endpoints - Validation - Authentication - Rate Limiting  â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

#### ğŸ”” **Notifications & Automation**                     â”‚

- Morning briefings (8:00 AM)â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

- Evening summaries (8:00 PM)â”‚                   Service Layer                             â”‚

- Email notifications for important eventsâ”‚  - Business Logic - AI Services - External Integrations     â”‚

- Automated job matching based on preferencesâ”‚  - Job Service - Analytics - Email - Content Generation     â”‚

- Smart reminders for follow-upsâ””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜

      â”‚              â”‚              â”‚                    â”‚

### Target Audienceâ”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”

â”‚PostgreSQLâ”‚  â”‚   Redis   â”‚  â”‚ ChromaDB â”‚  â”‚  External APIs â”‚

- **Job Seekers**: Professionals actively searching for new opportunitiesâ”‚ (Primary)â”‚  â”‚  (Cache)  â”‚  â”‚ (Vector) â”‚  â”‚ OpenAI, Groq   â”‚

- **Career Changers**: Individuals transitioning to data science, ML, or AI rolesâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ LinkedIn, etc. â”‚

- **Recent Graduates**: Entry to mid-level candidates entering the tech job market                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- **European Job Market**: Optimized for positions in Germany, Netherlands, France, UK, and other EU countriesâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚              Background Workers (Celery)                    â”‚

### Technology Highlightsâ”‚  - Job Scraping - Email Sending - Report Generation         â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- **Modern Stack**: FastAPI + Next.js + PostgreSQL```

- **AI Integration**: OpenAI GPT-4, Groq (Llama 3), Google Gemini

- **Real-time Updates**: WebSocket support for live notifications### Design Patterns

- **Scalable Architecture**: Async operations, background tasks with Celery

- **Secure**: OAuth 2.0, JWT authentication, encrypted API keys1. **Repository Pattern**: Data access abstraction with SQLAlchemy repositories

- **Production-Ready**: Docker support, monitoring, error tracking2. **Service Layer Pattern**: Business logic encapsulation in dedicated service classes

3. **Factory Pattern**: Dynamic LLM service instantiation based on configuration

---4. **Strategy Pattern**: Adaptive routing for AI model selection

5. **Observer Pattern**: Event-driven notifications and webhooks

6. **Dependency Injection**: FastAPI's dependency system for clean component wiring

### Directory Structure

```
career-copilot/
â”œâ”€â”€ backend/                    # Python FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/               # API endpoints (v1 versioning)
â”‚   â”‚   â”‚   â””â”€â”€ v1/           # Version 1 endpoints
â”‚   â”‚   â”œâ”€â”€ core/             # Core functionality
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py     # Settings & configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py   # Database setup
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py    # Logging configuration
â”‚   â”‚   â”‚   â””â”€â”€ security.py   # Security utilities
â”‚   â”‚   â”œâ”€â”€ models/           # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ schemas/          # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/         # Business logic services
â”‚   â”‚   â”œâ”€â”€ repositories/     # Data access layer
â”‚   â”‚   â”œâ”€â”€ middleware/       # Custom middleware
â”‚   â”‚   â”œâ”€â”€ tasks/            # Celery background tasks
â”‚   â”‚   â””â”€â”€ main.py           # FastAPI app entry point
â”‚   â”œâ”€â”€ alembic/              # Database migrations
â”‚   â”œâ”€â”€ tests/                # Backend tests
â”‚   â””â”€â”€ scripts/              # Utility scripts
â”œâ”€â”€ frontend/                  # Next.js React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/              # Next.js 14 app directory
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”œâ”€â”€ lib/              # Utilities & helpers
â”‚   â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”‚   â””â”€â”€ types/            # TypeScript type definitions
â”‚   â””â”€â”€ public/               # Static assets
â”œâ”€â”€ config/                    # Configuration files
â”‚   â”œâ”€â”€ llm_config.json       # LLM provider settings
â”‚   â”œâ”€â”€ application.yaml      # App configuration
â”‚   â””â”€â”€ environments/         # Env-specific configs
â”œâ”€â”€ deployment/               # Deployment configurations
â”‚   â”œâ”€â”€ docker/              # Docker & compose files
â”‚   â”œâ”€â”€ k8s/                 # Kubernetes manifests
â”‚   â””â”€â”€ nginx/               # Nginx configs
â”œâ”€â”€ monitoring/              # Observability configs
â”‚   â”œâ”€â”€ prometheus/          # Prometheus metrics
â”‚   â”œâ”€â”€ grafana/             # Grafana dashboards
â”‚   â””â”€â”€ loki/                # Log aggregation
â”œâ”€â”€ scripts/                 # Automation scripts
â”œâ”€â”€ tests/                   # Integration & E2E tests
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ .env.example             # Environment template
â””â”€â”€ pyproject.toml           # Python dependencies
```

---

## ğŸ› ï¸ Technology Stack

### Backend
- **Framework**: FastAPI 0.109+ (async Python web framework)
- **ORM**: SQLAlchemy 2.0+ with Alembic migrations
- **Database**: PostgreSQL (production), SQLite (development)
- **Caching**: Redis (session management, rate limiting)
- **Task Queue**: Celery with Redis broker
- **Authentication**: JWT tokens, OAuth2, PassLib with bcrypt
- **Validation**: Pydantic v2 with email validation
- **API Clients**: HTTPX (async), Requests

### Frontend
- **Framework**: Next.js 14 (React 18)
- **Language**: TypeScript
- **Styling**: TailwindCSS
- **UI Components**: Headless UI, Lucide React icons
- **Charts**: Recharts
- **HTTP Client**: Axios
- **Testing**: Jest, React Testing Library

### AI & Machine Learning
- **LLM Providers**: 
  - OpenAI GPT-4 & GPT-3.5-turbo
  - Groq (Llama 3.1, Mixtral)
  - Anthropic Claude 3
  - Google Gemini
- **Vector Database**: ChromaDB (semantic search)
- **Embeddings**: Sentence Transformers
- **PDF Processing**: PyMuPDF

### DevOps & Infrastructure
- **Containerization**: Docker, Docker Compose
- **Orchestration**: Kubernetes (optional)
- **CI/CD**: GitHub Actions
- **Monitoring**: Prometheus, Grafana, Loki
- **Web Server**: Nginx (reverse proxy)
- **Process Manager**: Gunicorn + Uvicorn workers
- **Deployment**: Render.com (cloud), self-hosted options

### Development Tools
- **Code Quality**: Ruff (linting/formatting), ESLint, Prettier
- **Type Checking**: MyPy (Python), TypeScript
- **Testing**: Pytest, Jest, Locust (load testing)
- **Security**: Bandit, Safety, Snyk
- **Pre-commit Hooks**: Pre-commit framework

---

## ğŸ“¦ Prerequisites

### Required Software

| Software   | Minimum Version | Purpose              |
| ---------- | --------------- | -------------------- |
| Python     | 3.11+           | Backend runtime      |
| Node.js    | 18.x+           | Frontend runtime     |
| npm/yarn   | 9.x+            | Package management   |
| PostgreSQL | 13+             | Production database  |
| Redis      | 6.x+            | Caching & task queue |
| Git        | 2.x+            | Version control      |

### Operating System Requirements
- **macOS**: 10.15+ (Catalina or later)
- **Linux**: Ubuntu 20.04+, Debian 11+, RHEL 8+, or equivalent
- **Windows**: Windows 10/11 with WSL2 recommended

### Hardware Requirements
- **RAM**: Minimum 4GB (8GB+ recommended for development)
- **Storage**: 5GB free disk space
- **CPU**: 2+ cores recommended

### Required Accounts & API Keys

You'll need accounts and API keys for the following services (see [External APIs & Services](#-external-apis--services)):

**Essential** (required for core functionality):
- OpenAI API key (for GPT models) OR Groq API key (free tier available)

**Optional** (for enhanced features):
- Anthropic API key (Claude models)
- Google Gemini API key
- LinkedIn API credentials (job scraping)
- Adzuna API credentials (job search)
- SendGrid API key (transactional emails)
- Google OAuth credentials (social login)
- GitHub OAuth credentials (social login)

---

## ğŸš€ Quick Start

Get up and running in 5 minutes:

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/career-copilot.git
cd career-copilot

# 2. Run the automated setup script
chmod +x scripts/setup.sh
./scripts/setup.sh

# 3. Configure your environment
cp .env.example .env
# Edit .env with your API keys (at minimum, add OPENAI_API_KEY or GROQ_API_KEY)

# 4. Start the application
make run-dev

# 5. Open your browser
# Backend API: http://localhost:8002/docs
# Frontend: http://localhost:3000
```

That's it! You now have a running instance of Career Copilot.

---

## ğŸ“¥ Installation & Setup

### Detailed Installation Steps

#### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/career-copilot.git
cd career-copilot
```

#### 2. Backend Setup

**Option A: Using the Setup Script (Recommended)**

```bash
chmod +x scripts/setup.sh
./scripts/setup.sh
```

The script will:
- Check prerequisites
- Create Python virtual environment
- Install backend dependencies
- Install frontend dependencies
- Set up environment files
- Initialize the database

**Option B: Manual Setup**

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install Python dependencies
pip install -U pip setuptools wheel
pip install -e ".[dev,ai,all]"

# Install pre-commit hooks
pre-commit install
```

#### 3. Frontend Setup

```bash
cd frontend
npm install
cd ..
```

#### 4. Environment Configuration

```bash
# Copy environment template
cp .env.example .env
cp backend/.env.example backend/.env

# Edit .env files with your configuration
# Required: DATABASE_URL, JWT_SECRET_KEY, at least one LLM API key
```

#### 5. Database Setup

**Using SQLite (Development)**

```bash
# Create data directory
mkdir -p data

# Run migrations
cd backend
alembic upgrade head
```

**Using PostgreSQL (Production)**

```bash
# Install PostgreSQL (if not already installed)
# macOS: brew install postgresql
# Ubuntu: sudo apt install postgresql postgresql-contrib

# Create database
createdb career_copilot

# Update .env with PostgreSQL connection string
# DATABASE_URL=postgresql://user:password@localhost:5432/career_copilot

# Run migrations
cd backend
alembic upgrade head
```

#### 6. Redis Setup (Optional, for caching)

```bash
# Install Redis
# macOS: brew install redis
# Ubuntu: sudo apt install redis-server

# Start Redis
# macOS: brew services start redis
# Ubuntu: sudo systemctl start redis
```

#### 7. Generate Secret Keys

```bash
# Generate JWT secret key
python -c "import secrets; print(secrets.token_urlsafe(32))"

# Add to .env:
# JWT_SECRET_KEY=<generated-key>
```

---

## ğŸ”Œ External APIs & Services

### LLM Providers

#### 1. OpenAI (GPT-4, GPT-3.5)

**Purpose**: High-quality text generation, analysis, and reasoning

**Get API Key**:
1. Visit [OpenAI Platform](https://platform.openai.com/)
2. Sign up or log in
3. Navigate to [API Keys](https://platform.openai.com/api-keys)
4. Click "Create new secret key"
5. Copy the key immediately (you won't see it again)

**Configuration**:
```bash
OPENAI_API_KEY=sk-...your-key-here...
OPENAI_MODEL=gpt-3.5-turbo  # or gpt-4 for better quality
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=4000
```

**Rate Limits**: 
- Free tier: 3 RPM, 40k TPM
- Tier 1: 500 RPM, 90k TPM
- See [OpenAI rate limits](https://platform.openai.com/docs/guides/rate-limits)

**Cost**: Pay-per-token pricing
- GPT-3.5-turbo: ~$0.002/1K tokens
- GPT-4: ~$0.03/1K tokens

---

#### 2. Groq (Llama 3.1, Mixtral) - **Recommended for Free Tier**

**Purpose**: Ultra-fast inference, cost-effective alternative to OpenAI

**Get API Key**:
1. Visit [Groq Console](https://console.groq.com/)
2. Sign up with email or GitHub
3. Go to [API Keys section](https://console.groq.com/keys)
4. Click "Create API Key"
5. Name your key and copy it

**Configuration**:
```bash
GROQ_API_KEY=gsk_...your-key-here...
GROQ_MODEL=llama-3.1-8b-instant  # or mixtral-8x7b-32768
GROQ_ENABLED=true
```

**Rate Limits**:
- Free tier: 30 RPM, 14,400 requests/day
- Very generous limits for a free service

**Cost**: FREE for reasonable usage

---

#### 3. Anthropic (Claude)

**Purpose**: Long-context analysis, safety-focused generation

**Get API Key**:
1. Visit [Anthropic Console](https://console.anthropic.com/)
2. Sign up for an account
3. Navigate to API Keys
4. Generate a new key

**Configuration**:
```bash
ANTHROPIC_API_KEY=sk-ant-...your-key-here...
ANTHROPIC_MODEL=claude-3-sonnet-20240229
```

---

#### 4. Google Gemini

**Purpose**: Multimodal capabilities, Google ecosystem integration

**Get API Key**:
1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Sign in with Google account
3. Click "Create API Key"
4. Select or create a Google Cloud project
5. Copy the generated key

**Configuration**:
```bash
GEMINI_API_KEY=...your-key-here...
```

---

### Job Boards & Scraping APIs

#### 5. Adzuna API

**Purpose**: Job search aggregation

**Get Credentials**:
1. Visit [Adzuna Developer Portal](https://developer.adzuna.com/)
2. Sign up for a developer account
3. Create a new application
4. Copy Application ID and API Key

**Configuration**:
```bash
ADZUNA_APP_ID=your_app_id
ADZUNA_APP_KEY=your_api_key
```

**Rate Limits**: 250 calls/month (free tier)

---

#### 6. LinkedIn API

**Purpose**: Job scraping and profile integration

**Get Credentials**:
1. Visit [LinkedIn Developers](https://www.linkedin.com/developers/)
2. Create an app
3. Request API access (approval required)
4. Get Client ID and Secret from app settings

**Configuration**:
```bash
LINKEDIN_API_CLIENT_ID=your_client_id
LINKEDIN_API_CLIENT_SECRET=your_client_secret
LINKEDIN_ACCESS_TOKEN=your_access_token
```

**Note**: LinkedIn API access requires application approval and has strict usage policies.

---

### Email Services

#### 7. SendGrid

**Purpose**: Transactional email delivery

**Get API Key**:
1. Visit [SendGrid](https://sendgrid.com/)
2. Sign up for a free account (100 emails/day free)
3. Go to Settings â†’ [API Keys](https://app.sendgrid.com/settings/api_keys)
4. Create a new API key with "Full Access" or "Mail Send" permissions

**Configuration**:
```bash
SENDGRID_API_KEY=SG....your-key-here...
SMTP_ENABLED=true
```

**Alternative**: Use standard SMTP (Gmail, Outlook, etc.)
```bash
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your_email@gmail.com
SMTP_PASSWORD=your_app_password  # Use app-specific password for Gmail
```

---

### OAuth Providers

#### 8. Google OAuth

**Purpose**: Social login, Google account integration

**Setup**:
1. Visit [Google Cloud Console](https://console.cloud.google.com/)
2. Create a new project or select existing
3. Enable Google+ API
4. Go to Credentials â†’ Create Credentials â†’ OAuth 2.0 Client ID
5. Configure consent screen
6. Add authorized redirect URIs: `http://localhost:8002/api/v1/oauth/google/callback`
7. Copy Client ID and Secret

**Configuration**:
```bash
GOOGLE_CLIENT_ID=your_client_id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=your_client_secret
```

---

#### 9. GitHub OAuth

**Purpose**: GitHub-based authentication

**Setup**:
1. Visit [GitHub Developer Settings](https://github.com/settings/developers)
2. Click "New OAuth App"
3. Fill in application details
4. Set callback URL: `http://localhost:8002/api/v1/oauth/github/callback`
5. Copy Client ID and generate Client Secret

**Configuration**:
```bash
GITHUB_CLIENT_ID=your_client_id
GITHUB_CLIENT_SECRET=your_client_secret
```

---

### Summary of API Key Requirements

| Service       | Required?          | Free Tier Available | Primary Use Case    |
| ------------- | ------------------ | ------------------- | ------------------- |
| OpenAI / Groq | **Yes** (pick one) | Groq: Yes           | AI-powered features |
| Anthropic     | Optional           | No                  | Alternative LLM     |
| Gemini        | Optional           | Yes                 | Alternative LLM     |
| Adzuna        | Optional           | Yes                 | Job aggregation     |
| LinkedIn      | Optional           | No*                 | Job scraping        |
| SendGrid      | Optional           | Yes (100/day)       | Email notifications |
| Google OAuth  | Optional           | Yes                 | Social login        |
| GitHub OAuth  | Optional           | Yes                 | Social login        |

*LinkedIn API requires application approval

---

## âš™ï¸ Configuration

### Environment Variables

Career Copilot uses a hierarchical configuration system:
1. `.env` file (root directory)
2. Environment-specific overrides in `config/environments/`
3. Runtime environment variables

#### Core Application Settings

```bash
# Environment mode: development, production, testing
ENVIRONMENT=development

# Enable debug mode (shows detailed errors, enables FastAPI docs)
DEBUG=true

# API server configuration
API_HOST=0.0.0.0
API_PORT=8002
```

#### Database Configuration

```bash
# SQLite (Development)
DATABASE_URL=sqlite:///./data/career_copilot.db

# PostgreSQL (Production)
DATABASE_URL=postgresql://user:password@localhost:5432/career_copilot

# Connection pool settings
DB_MAX_CONNECTIONS=20
DB_TIMEOUT=30
```

#### Authentication & Security

```bash
# JWT configuration (REQUIRED)
# Generate: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production-min-32-chars
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# CORS allowed origins (comma-separated)
CORS_ORIGINS=http://localhost:8501,http://localhost:3000
```

#### AI/LLM Configuration

```bash
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=4000

# Groq (recommended for free tier)
GROQ_API_KEY=gsk_...
GROQ_MODEL=llama-3.1-8b-instant
GROQ_ENABLED=true

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Google Gemini
GEMINI_API_KEY=...
```

#### Vector Database

```bash
CHROMA_PERSIST_DIRECTORY=./data/chroma
CHROMA_COLLECTION_NAME=job_embeddings
```

#### Email & Notifications

```bash
# Email toggle
SMTP_ENABLED=false

# SMTP Configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your_email@gmail.com
SMTP_PASSWORD=your_app_password
SMTP_FROM_EMAIL=notifications@career-copilot.com
SMTP_FROM_NAME=Career Copilot

# SendGrid Alternative
SENDGRID_API_KEY=SG...

# Notification scheduling
DAILY_DIGEST_TIME=08:00
WEEKLY_SUMMARY_DAY=MONDAY
WEEKLY_SUMMARY_TIME=09:00
```

#### Job Processing

```bash
MAX_JOBS_PER_FETCH=100
JOB_REFRESH_INTERVAL_HOURS=24
JOB_RETENTION_DAYS=30
```

#### Redis Cache (Optional)

```bash
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
```

#### Rate Limiting

```bash
RATE_LIMIT_ENABLED=true
MAX_REQUESTS_PER_MINUTE=60
```

#### Logging

```bash
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE_PATH=./logs/app.log
```

### LLM Configuration File

Advanced LLM routing is configured in `config/llm_config.json`:

```json
{
  "providers": {
    "groq-mixtral": {
      "provider": "groq",
      "model_name": "mixtral-8x7b-32768",
      "api_key": null,  // Set via GROQ_API_KEY env var
      "temperature": 0.1,
      "max_tokens": 4000,
      "priority": 1,
      "capabilities": ["fast_generation", "analysis"],
      "enabled": true
    }
  },
  "routing": {
    "default_strategy": "adaptive",
    "fallback_enabled": true
  }
}
```

### Security Best Practices

âš ï¸ **IMPORTANT**:
1. **Never commit `.env` files** to version control
2. **Rotate secrets regularly** (JWT keys, API keys)
3. **Use strong passwords** (min 32 characters for JWT secret)
4. **Enable HTTPS** in production
5. **Restrict CORS origins** to trusted domains only
6. **Use environment variables** for secrets in production (not `.env` files)

---

## ğŸ“– Usage & Functionality

### Starting the Application

#### Development Mode

**Option 1: Using Make (Recommended)**

```bash
# Start both backend and frontend
make run-dev

# Or individually:
make run-backend  # Start FastAPI server on :8002
make run-frontend # Start Next.js dev server on :3000
```

**Option 2: Manual Start**

```bash
# Terminal 1 - Backend
cd backend
source ../venv/bin/activate  # Activate virtual environment
uvicorn app.main:app --reload --host 0.0.0.0 --port 8002

# Terminal 2 - Frontend
cd frontend
npm run dev

# Terminal 3 - Celery Worker (optional, for background tasks)
cd backend
celery -A app.celery worker --loglevel=info
```

#### Access Points

- **Frontend UI**: http://localhost:3000
- **Backend API Docs**: http://localhost:8002/docs (Swagger UI)
- **Alternative API Docs**: http://localhost:8002/redoc (ReDoc)
- **Health Check**: http://localhost:8002/api/v1/health

---

### Main User Workflows

#### 1. User Registration & Authentication

```bash
# Register new user
curl -X POST http://localhost:8002/api/v1/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "username": "johndoe",
    "email": "john@example.com",
    "password": "SecurePass123!"
  }'

# Login
curl -X POST http://localhost:8002/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "username": "johndoe",
    "password": "SecurePass123!"
  }'
# Returns: {"access_token": "eyJ...", "token_type": "bearer"}
```

#### 2. Job Management

**Add a Job Manually**:
```bash
curl -X POST http://localhost:8002/api/v1/jobs \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "company": "Tech Corp",
    "title": "Senior Software Engineer",
    "location": "San Francisco, CA",
    "description": "We are looking for...",
    "requirements": "5+ years experience...",
    "salary_range": "$120k-$180k",
    "job_type": "full-time",
    "remote_option": "hybrid",
    "tech_stack": ["Python", "React", "PostgreSQL"],
    "application_url": "https://techcorp.com/careers/12345"
  }'
```

**Search Jobs with AI**:
```bash
curl -X GET "http://localhost:8002/api/v1/jobs/search?query=python+developer&location=remote" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

#### 3. Application Tracking

**Create Application**:
```bash
curl -X POST http://localhost:8002/api/v1/applications \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "job_id": 1,
    "status": "applied",
    "applied_date": "2024-01-15",
    "notes": "Submitted through company website"
  }'
```

**Update Application Status**:
```bash
curl -X PATCH http://localhost:8002/api/v1/applications/1 \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "status": "interview",
    "interview_date": "2024-01-25T14:00:00"
  }'
```

#### 4. AI Content Generation

**Generate Cover Letter**:
```bash
curl -X POST http://localhost:8002/api/v1/content/generate/cover-letter \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "job_id": 1,
    "tone": "professional",
    "highlights": ["leadership experience", "Python expertise"]
  }'
```

**Tailor Resume**:
```bash
curl -X POST http://localhost:8002/api/v1/content/generate/resume \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "job_id": 1,
    "template": "modern",
    "sections": ["experience", "skills", "education"]
  }'
```

#### 5. Interview Practice

**Start Interview Session**:
```bash
curl -X POST http://localhost:8002/api/v1/interview/start \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "job_id": 1,
    "interview_type": "technical",
    "difficulty": "medium"
  }'
```

---

### Running Tests

```bash
# Run all tests
make test

# Backend tests only
make test-python

# Frontend tests only
make test-frontend

# Run with coverage
pytest --cov=backend --cov-report=html
npm run test:coverage

# Run specific test file
pytest backend/tests/unit/test_auth_service.py

# Run tests in watch mode (frontend)
npm run test:watch
```

---

### Code Quality Checks

```bash
# Run all quality checks
make quality-check

# Format code (auto-fix)
make format

# Linting
make lint

# Type checking
make type-check

# Security scanning
make security
```

---

## ğŸ”Œ API Documentation

### Base URL

```
http://localhost:8002/api/v1
```

### Authentication

All endpoints (except `/auth/register` and `/auth/login`) require a Bearer token:

```bash
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

### Core Endpoints

#### Authentication

| Method | Endpoint         | Description                 | Auth Required |
| ------ | ---------------- | --------------------------- | ------------- |
| POST   | `/auth/register` | Create new user account     | No            |
| POST   | `/auth/login`    | Login and receive JWT token | No            |
| POST   | `/auth/logout`   | Invalidate current token    | Yes           |
| GET    | `/auth/me`       | Get current user info       | Yes           |
| POST   | `/auth/refresh`  | Refresh access token        | Yes           |

#### Jobs

| Method | Endpoint                | Description              |
| ------ | ----------------------- | ------------------------ |
| GET    | `/jobs`                 | List all jobs for user   |
| POST   | `/jobs`                 | Create new job           |
| GET    | `/jobs/{id}`            | Get job details          |
| PATCH  | `/jobs/{id}`            | Update job               |
| DELETE | `/jobs/{id}`            | Delete job               |
| GET    | `/jobs/search`          | Search jobs with filters |
| GET    | `/jobs/recommendations` | Get AI-recommended jobs  |

#### Applications

| Method | Endpoint              | Description                |
| ------ | --------------------- | -------------------------- |
| GET    | `/applications`       | List all applications      |
| POST   | `/applications`       | Create application         |
| GET    | `/applications/{id}`  | Get application details    |
| PATCH  | `/applications/{id}`  | Update application status  |
| DELETE | `/applications/{id}`  | Delete application         |
| GET    | `/applications/stats` | Get application statistics |

#### Content Generation

| Method | Endpoint                         | Description              |
| ------ | -------------------------------- | ------------------------ |
| POST   | `/content/generate/resume`       | Generate tailored resume |
| POST   | `/content/generate/cover-letter` | Generate cover letter    |
| GET    | `/content/history`               | Get generation history   |
| GET    | `/content/{id}`                  | Get specific content     |

#### Analytics

| Method | Endpoint                     | Description                  |
| ------ | ---------------------------- | ---------------------------- |
| GET    | `/analytics/dashboard`       | Get dashboard metrics        |
| GET    | `/analytics/trends`          | Application trends over time |
| GET    | `/analytics/success-rate`    | Calculate success rates      |
| GET    | `/analytics/recommendations` | AI-driven insights           |

#### Interview Practice

| Method | Endpoint                  | Description                |
| ------ | ------------------------- | -------------------------- |
| POST   | `/interview/start`        | Start practice session     |
| POST   | `/interview/answer`       | Submit answer for feedback |
| GET    | `/interview/history`      | Get past sessions          |
| GET    | `/interview/{session_id}` | Get session details        |

### Request/Response Examples

**Create Job**:

```json
// POST /api/v1/jobs
{
  "company": "Acme Corp",
  "title": "Backend Developer",
  "location": "Remote",
  "description": "Looking for experienced developer...",
  "tech_stack": ["Python", "FastAPI", "PostgreSQL"],
  "salary_min": 100000,
  "salary_max": 150000,
  "job_type": "full-time",
  "remote_option": "remote"
}

// Response: 201 Created
{
  "id": 42,
  "user_id": 1,
  "company": "Acme Corp",
  "title": "Backend Developer",
  "location": "Remote",
  "created_at": "2024-01-15T10:30:00Z",
  // ... other fields
}
```

**Get Application Stats**:

```json
// GET /api/v1/applications/stats

// Response: 200 OK
{
  "total_applications": 45,
  "by_status": {
    "applied": 20,
    "interview": 5,
    "offer": 2,
    "rejected": 15,
    "accepted": 3
  },
  "success_rate": 0.111,
  "average_response_time_days": 7.5,
  "upcoming_interviews": 2
}
```

### WebSocket Endpoints

**Real-time Progress Updates**:

```javascript
const ws = new WebSocket('ws://localhost:8002/ws/progress');

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Progress update:', data);
};
```

### Error Responses

```json
// 400 Bad Request
{
  "detail": "Validation error",
  "errors": [
    {
      "field": "email",
      "message": "Invalid email format"
    }
  ]
}

// 401 Unauthorized
{
  "detail": "Invalid or expired token"
}

// 404 Not Found
{
  "detail": "Job with id 999 not found"
}

// 500 Internal Server Error
{
  "detail": "An unexpected error occurred",
  "request_id": "abc-123-def"
}
```

---

## ğŸ‘¨â€ğŸ’» Development Guidelines

### Code Style

#### Python (Backend)

- **Formatter**: Ruff (replaces Black + isort)
- **Linter**: Ruff (replaces Flake8)
- **Type Checker**: MyPy
- **Docstrings**: Google-style

```python
from typing import List, Optional
from pydantic import BaseModel

class JobCreate(BaseModel):
    """Schema for creating a new job posting.
    
    Attributes:
        company: Name of the hiring company
        title: Job title/position
        location: Geographic location or "Remote"
    """
    company: str
    title: str
    location: Optional[str] = None
```

#### TypeScript (Frontend)

- **Formatter**: Prettier
- **Linter**: ESLint with TypeScript plugin
- **Style**: Functional components, hooks

```typescript
interface Job {
  id: number;
  company: string;
  title: string;
  location?: string;
}

export const JobCard: React.FC<{ job: Job }> = ({ job }) => {
  return (
    <div className="p-4 border rounded">
      <h3 className="text-lg font-bold">{job.title}</h3>
      <p className="text-gray-600">{job.company}</p>
    </div>
  );
};
```

### Git Workflow

```bash
# Create feature branch
git checkout -b feature/job-recommendations

# Make changes and commit
git add .
git commit -m "feat: add AI-powered job recommendations"

# Commit message format: <type>: <description>
# Types: feat, fix, docs, style, refactor, test, chore
```

### Pre-commit Hooks

Automatically run on every commit:
- Code formatting (Ruff, Prettier)
- Linting (Ruff, ESLint)
- Type checking (MyPy, TypeScript)
- Security checks (Bandit)

```bash
# Install hooks
pre-commit install

# Run manually
pre-commit run --all-files
```

### Testing Requirements

- **Unit Tests**: Required for all new services and utilities
- **Integration Tests**: Required for API endpoints
- **Coverage Target**: Minimum 80% code coverage

```python
# Example test
def test_create_job(client, auth_headers, db):
    """Test creating a new job posting."""
    payload = {
        "company": "Test Corp",
        "title": "Developer",
        "location": "Remote"
    }
    response = client.post("/api/v1/jobs", json=payload, headers=auth_headers)
    assert response.status_code == 201
    assert response.json()["company"] == "Test Corp"
```

### Database Migrations

```bash
# Create new migration
cd backend
alembic revision --autogenerate -m "Add interview feedback column"

# Review generated migration in backend/alembic/versions/

# Apply migration
alembic upgrade head

# Rollback one version
alembic downgrade -1
```

### Pull Request Process

1. Create feature branch from `main`
2. Implement feature with tests
3. Run quality checks: `make quality-check`
4. Ensure all tests pass: `make test`
5. Push and create PR with description
6. Request code review
7. Address review comments
8. Merge after approval

---

## ğŸ› Troubleshooting

### Common Issues

#### 1. Database Connection Error

**Problem**: `sqlalchemy.exc.OperationalError: unable to open database file`

**Solution**:
```bash
# Create data directory
mkdir -p data

# Check DATABASE_URL in .env
# Should be: sqlite:///./data/career_copilot.db
```

---

#### 2. ModuleNotFoundError

**Problem**: `ModuleNotFoundError: No module named 'app'`

**Solution**:
```bash
# Ensure you're in the project root
cd /path/to/career-copilot

# Activate virtual environment
source venv/bin/activate

# Reinstall in editable mode
pip install -e .
```

---

#### 3. JWT Token Errors

**Problem**: `401 Unauthorized: Invalid or expired token`

**Solution**:
```bash
# 1. Ensure JWT_SECRET_KEY is set in .env
# 2. Generate a new secret if needed
python -c "import secrets; print(secrets.token_urlsafe(32))"

# 3. Restart backend server
# 4. Login again to get fresh token
```

---

#### 4. OpenAI API Errors

**Problem**: `openai.error.AuthenticationError: Incorrect API key`

**Solution**:
```bash
# 1. Verify API key in .env
echo $OPENAI_API_KEY  # Should start with sk-

# 2. Test API key
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"

# 3. Generate new key at https://platform.openai.com/api-keys
```

---

#### 5. Frontend Can't Connect to Backend

**Problem**: `Network Error` or `CORS policy` errors

**Solution**:
```bash
# 1. Verify backend is running
curl http://localhost:8002/api/v1/health

# 2. Check CORS_ORIGINS in .env includes frontend URL
CORS_ORIGINS=http://localhost:3000,http://localhost:8501

# 3. Restart backend after changes
```

---

#### 6. Redis Connection Error

**Problem**: `redis.exceptions.ConnectionError`

**Solution**:
```bash
# Check if Redis is running
redis-cli ping  # Should return PONG

# Start Redis
# macOS: brew services start redis
# Ubuntu: sudo systemctl start redis

# Or disable Redis in .env
REDIS_ENABLED=false
```

---

### Debug Mode

Enable detailed error logging:

```bash
# In .env
DEBUG=true
LOG_LEVEL=DEBUG

# View logs
tail -f logs/app.log
```

### Getting Help

1. **Check the logs**: `logs/app.log` for backend, browser console for frontend
2. **API Documentation**: Visit http://localhost:8002/docs for interactive API testing
3. **GitHub Issues**: Search existing issues or create a new one
4. **Documentation**: Check `docs/` folder for detailed guides

---

## ğŸš€ Production Deployment

### Pre-Deployment Checklist

- [ ] Set `ENVIRONMENT=production` in environment variables
- [ ] Set `DEBUG=false`
- [ ] Use PostgreSQL (not SQLite)
- [ ] Generate strong JWT secret (32+ characters)
- [ ] Configure production database backups
- [ ] Set up HTTPS/SSL certificates
- [ ] Restrict CORS to production domain only
- [ ] Enable rate limiting
- [ ] Configure production logging (Sentry, CloudWatch, etc.)
- [ ] Set up monitoring and alerts
- [ ] Review all API keys and rotate if needed

### Environment-Specific Configuration

```bash
# Production .env differences
ENVIRONMENT=production
DEBUG=false
DATABASE_URL=postgresql://user:password@prod-db:5432/career_copilot
CORS_ORIGINS=https://your-domain.com
JWT_EXPIRATION_HOURS=2  # Shorter for security
RATE_LIMIT_ENABLED=true
```

### Deployment Options

#### Option 1: Render.com (Recommended for Easy Deploy)

The project includes a `render.yaml` configuration:

```bash
# 1. Create Render account at https://render.com
# 2. Connect your GitHub repository
# 3. Render will auto-detect render.yaml
# 4. Add environment variables in Render dashboard
# 5. Deploy!
```

#### Option 2: Docker Compose

```bash
# Build images
docker-compose -f deployment/docker/docker-compose.yml build

# Start services
docker-compose -f deployment/docker/docker-compose.yml up -d

# Check status
docker-compose ps
```

#### Option 3: Kubernetes

```bash
# Apply manifests
kubectl apply -f deployment/k8s/

# Check deployment
kubectl get pods -n career-copilot
```

#### Option 4: Traditional Server

```bash
# On server (Ubuntu example)
# 1. Install dependencies
sudo apt update
sudo apt install python3.11 python3-pip postgresql nginx redis-server

# 2. Clone repository
git clone https://github.com/yourusername/career-copilot.git
cd career-copilot

# 3. Set up Python environment
python3.11 -m venv venv
source venv/bin/activate
pip install -e ".[all]"

# 4. Configure environment
cp .env.example .env
nano .env  # Edit with production values

# 5. Set up database
sudo -u postgres createdb career_copilot
alembic upgrade head

# 6. Build frontend
cd frontend
npm install
npm run build

# 7. Set up systemd services
sudo cp deployment/services/*.service /etc/systemd/system/
sudo systemctl enable career-copilot-backend
sudo systemctl start career-copilot-backend

# 8. Configure Nginx
sudo cp deployment/nginx/career-copilot.conf /etc/nginx/sites-available/
sudo ln -s /etc/nginx/sites-available/career-copilot.conf /etc/nginx/sites-enabled/
sudo systemctl restart nginx
```

### Performance Optimization

```bash
# Backend
# Use Gunicorn with multiple workers
gunicorn backend.app.main:app \
  -w 4 \
  -k uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8002

# Frontend
# Enable production optimizations
npm run build  # Creates optimized production build
npm run start  # Serves production build
```

### Monitoring & Observability

**Prometheus Metrics**: http://your-domain.com/metrics

**Health Checks**:
```bash
# Liveness
curl http://your-domain.com/api/v1/health

# Readiness
curl http://your-domain.com/api/v1/health/ready
```

**Log Aggregation**:
- Configured with Loki/Promtail (see `monitoring/loki-config.yaml`)
- Alternatively, integrate with CloudWatch, Datadog, or Elasticsearch

### Backup Strategy

```bash
# Automated backups (configured in .env)
BACKUP_ENABLED=true
BACKUP_SCHEDULE=0 2 * * *  # Daily at 2 AM
BACKUP_RETENTION_DAYS=30

# Manual backup
cd backend
python -m app.cli backup create --name manual-backup

# Restore from backup
python -m app.cli backup restore --file backups/manual-backup.sql
```

### Security Hardening

1. **Enable HTTPS**: Use Let's Encrypt or cloud provider SSL
2. **Firewall**: Only expose ports 80, 443
3. **Database**: Use connection pooling, prepared statements
4. **Secrets**: Use environment variables or secret managers (AWS Secrets Manager, HashiCorp Vault)
5. **Rate Limiting**: Enable and tune for your traffic
6. **WAF**: Consider Cloudflare or AWS WAF
7. **Updates**: Regularly update dependencies

---

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

### Ways to Contribute

- ğŸ› **Report bugs**: Open an issue with details
- ğŸ’¡ **Suggest features**: Describe your use case
- ğŸ“ **Improve documentation**: Fix typos, add examples
- ğŸ”§ **Submit code**: Fix bugs, implement features

### Development Setup

```bash
# 1. Fork the repository on GitHub
# 2. Clone your fork
git clone https://github.com/YOUR_USERNAME/career-copilot.git
cd career-copilot

# 3. Add upstream remote
git remote add upstream https://github.com/ORIGINAL_OWNER/career-copilot.git

# 4. Create feature branch
git checkout -b feature/your-feature-name

# 5. Make changes, commit, push
git add .
git commit -m "feat: add amazing feature"
git push origin feature/your-feature-name

# 6. Open Pull Request on GitHub
```

### Code Review Process

1. All PRs require at least one approval
2. CI checks must pass (tests, linting, type checking)
3. Code coverage must not decrease
4. Documentation updated if needed

### Release Process

```bash
# Version bump
# Update VERSION file
echo "1.2.0" > VERSION

# Tag release
git tag -a v1.2.0 -m "Release v1.2.0"
git push origin v1.2.0
```

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2024 Career Copilot Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

[Full license text in LICENSE file]
```

---

## ğŸ“ Contact & Support

### Get Help

- **Documentation**: Check the `docs/` folder
- **GitHub Issues**: https://github.com/yourusername/career-copilot/issues
- **Discussions**: https://github.com/yourusername/career-copilot/discussions

### Project Team

- **Maintainers**: Career Copilot Team
- **Email**: team@career-copilot.com

### Stay Updated

- â­ Star the repository
- ğŸ‘ï¸ Watch for updates
- ğŸ´ Fork to contribute

---

## ğŸ™ Acknowledgments

This project leverages amazing open-source technologies:

- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [Next.js](https://nextjs.org/) - React framework for production
- [SQLAlchemy](https://www.sqlalchemy.org/) - Python SQL toolkit and ORM
- [OpenAI](https://openai.com/) - GPT language models
- [Groq](https://groq.com/) - Ultra-fast inference
- [ChromaDB](https://www.trychroma.com/) - AI-native vector database

---

## ğŸ“Š Project Status

**Current Version**: 1.0.0
**Status**: âœ… Production Ready
**Last Updated**: October 2025

### Roadmap

- [ ] Mobile app (React Native)
- [ ] LinkedIn job auto-apply
- [ ] Advanced salary negotiation AI
- [ ] Team collaboration features
- [ ] Browser extension for job tracking
- [ ] Integration with ATS systems

---

<div align="center">

**Made with â¤ï¸ by the Career Copilot Team**

[â¬† Back to Top](#career-copilot-)

</div>
